import pandas as pd
import numpy as np


wbcd=pd.read_csv('wbcd.csv')
#theere are 569 rows and 12 columns
wbcd.describe()
#In the output there is only B for benign and M for Maligant



wbcd.columns
wbcd.head()


#let us first convert it as Benign and Maligant
#Benign=Non cancerous
#Maligant=cancerous
wbcd['diagnosis']=np.where(wbcd['diagnosis']=='B','Benign',wbcd['diagnosis'])
#In the wbcd there is column named 'diagnosisi ehere there is B replace to Benign.Similary for M to Maligant
wbcd['diagnosis']=np.where(wbcd['diagnosis']=='M','Maligant',wbcd['diagnosis'])


wbcd.head()


#0th column is patient ID let us drop it
wbcd=wbcd.iloc[:,1:32]


#Normalization
def norm_func(i):
    x=(i-i.min())/(i.max()-i.min())
    return x


#Let us apply this function to the dataframe
wbcd_n=norm_func(wbcd.iloc[:,1:32])
#Because now 0th column id output or label it is not considered hence 1:all


#Let us now apply X as input And Y as output
X=np.array(wbcd_n.iloc[:,:])
#since in wbcd_n we are already excluding output columns hence all rows and
y=np.array(wbcd['diagnosis'])


#Now let us split the data into training and testing
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)
#Here you are  passing X,y instead dataframe handle
#There could be chances of unbalancing of data


#Let us assume that you have 100 data points out of which 80 NC and 20 Cancer
#This data points must be wqually distributedabs
#There is satisfied sampling concept used
from sklearn.neighbors import KNeighborsClassifier
knn=KNeighborsClassifier(n_neighbors=21)
knn.fit(X_train,y_train)
pred=knn.predict(X_test)
pred


#Now let us evaluate the model
from sklearn.metrics import accuracy_score
print(accuracy_score(pred,y_test))
pd.crosstab(pred,y_test)


#Let us check the aplicability of the model
#i.e missClassification,Actual patient is maligant
#i.e cancer patient not predicted is Benign is 1.
#Actual patient is Benign and predicted as cancer patient is 5.
#Hence this model is not suitable for the given problem


#let us try to select correct value of k
acc=[]
#Running KNN algorithm for k=3 to 50 in steps of 2
for i in range(3,50,2):
    neigh=KNeighborsClassifier(n_neighbors=i)
    neigh.fit(X_train,y_train)
    train_acc=np.mean(neigh.predict(X_train)==y_train)
    test_acc=np.mean(neigh.predict(X_test)==y_test)
    acc.append([train_acc,test_acc])


#If you will see the acc,it has got accuracy,i[0].train_acc
#i[1]=test_acc
#To plot the graph of train_acc and test_acc
import matplotlib.pyplot as plt
plt.plot(np.arange(3,50,2),[i[0] for i in acc],'ro-')
plt.plot(np.arange(3,50,2),[i[1] for i in acc],'bo-')


#There are 3,5,7 and 9 are possibility values where accuracy is good
#let us check for k=3
knn=KNeighborsClassifier(n_neighbors=9)
knn.fit(X_train,y_train)
pred=knn.predict(X_test)
print(accuracy_score(y_test,pred))
pd.crosstab(y_test,pred)


#i.e miss Classification ,Actual pateint is Maligant


















